{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "This is an extension of the Credit Card Fraud Detection mini project in my repo. Here I overcome the two hidden gaps (Gridsearch and Threshold tuning against the Test dataset) in the original mini-project.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\HP\\Documents\\DataScience\\Python Scripts\\Credit Card\\ULB\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the data\n",
    "As see in the plot below, this data is heavly imbalanced. About 99.8% of the records are negative i.e non-fradulent records. Such heavy class imbalance needs to be handled with care as usual evaluation metrics such as accuracy don't hold good. Use case specific metrics such as Recall, Precision, True-Negative-Rate etc can be used as evaluation metrics.\n",
    "\n",
    "Given the nature of his dataset i.e highly imbalanced and huge significance associated with finding a fradulent transactions, I have chosen Recall (primary metric) and precision, f1-score as secondary metrics.\n",
    "\n",
    "While building classification model, I will leverage 'class_weight' parameter in Scikit-Learn to overcame the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"Class\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99827251436937992"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imb_Q = data.loc[data.Class == 0, \"Class\"].count()/len(data.Class)\n",
    "Imb_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "There are no missing values in this dataset as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the model for hyper parameters\n",
    "Hyper-parameter tuning for the classifier (LinearSVC) for C and 'class weight' (since this is an heavily imbalanced dataset) is done. Towards this the Training dataset is split into CV folds (two in this case) and then custom gridsearchCV is done to find the best C & 'class weight' values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns= colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_X = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_y = scaled_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del scaled_X['Time']\n",
    "del scaled_X['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s_train, X_s_test, y_s_train, y_s_test = train_test_split(scaled_X, scaled_y, test_size=0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s_train1, X_s_train2, y_s_train1, y_s_train2 = train_test_split(X_s_train, y_s_train, test_size=0.5, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom GridsearchCV - Turning for C &  Classweights - CV Block-1\n",
    "Custom script (below) is run on CV Block-1 against a range of C(0.05, 0.1, 1, 10) and Class weights({0: 0.1, 1: 0.9}, {0: 0.05, 1: 0.95}, {0: 0.04, 1: 0.96}, {0: 0.03, 1: 0.97}, {0: 0.02, 1: 0.98}). Models are trained on Train-Split-1 with values in this C & Classweight grid and validated against Train-Split-2 (not on Test split)\n",
    "\n",
    "Basis this the best params found are: C 1 Classweights {0: 0.1, 1: 0.9} that resulted in Recall of 83 and Precision of 80 and f1-score of 82. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 0.05 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99563\n",
      "         1.0       0.61      0.85      0.71       119\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.80      0.92      0.85     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99557\n",
      "         1.0       0.64      0.85      0.73       125\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.82      0.92      0.86     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99554\n",
      "         1.0       0.64      0.84      0.73       128\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.82      0.92      0.86     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99552\n",
      "         1.0       0.66      0.84      0.74       130\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.83      0.92      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99551\n",
      "         1.0       0.66      0.83      0.73       131\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.83      0.92      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99549\n",
      "         1.0       0.67      0.83      0.74       133\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.83      0.92      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99546\n",
      "         1.0       0.69      0.84      0.75       136\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.84      0.92      0.88     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99542\n",
      "         1.0       0.71      0.84      0.77       140\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.86      0.92      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99541\n",
      "         1.0       0.72      0.84      0.78       141\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.86      0.92      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99539\n",
      "         1.0       0.73      0.85      0.78       143\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.86      0.92      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99522\n",
      "         1.0       0.80      0.83      0.82       160\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.92      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99518\n",
      "         1.0       0.81      0.82      0.81       164\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.91      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99503\n",
      "         1.0       0.81      0.75      0.78       179\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.88      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99501\n",
      "         1.0       0.81      0.75      0.78       181\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.87      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99491\n",
      "         1.0       0.83      0.72      0.77       191\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.92      0.86      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99520\n",
      "         1.0       0.80      0.82      0.81       162\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.91      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99502\n",
      "         1.0       0.81      0.75      0.78       180\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.87      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99499\n",
      "         1.0       0.81      0.74      0.77       183\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.87      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99494\n",
      "         1.0       0.83      0.73      0.78       188\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.92      0.87      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99485\n",
      "         1.0       0.83      0.70      0.76       197\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.92      0.85      0.88     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [0.05, 0.1, 1, 10]\n",
    "ClassWeights =[{0: 0.1, 1: 0.9}, {0: 0.05, 1: 0.95}, {0: 0.04, 1: 0.96}, {0: 0.03, 1: 0.97}, {0: 0.02, 1: 0.98}]\n",
    "for i in C:\n",
    "    for j in ClassWeights:\n",
    "        model_svc = LinearSVC(C=i, class_weight = j)\n",
    "        model_svc.fit(X_s_train1, y_s_train1)\n",
    "        y_s_pred2 = model_svc.predict(X_s_train2)\n",
    "        print(\"Classification Report for C {0} Classweights {1} is: {2}\".format(i, j, classification_report(y_s_pred2, y_s_train2)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom GridsearchCV - Turning for C &  Classweights - CV Block-2\n",
    "Custom script (below) is run on CV Block-2 against a range of C(0.05, 0.1, 1, 10) and Class weights({0: 0.1, 1: 0.9}, {0: 0.05, 1: 0.95}, {0: 0.04, 1: 0.96}, {0: 0.03, 1: 0.97}, {0: 0.02, 1: 0.98}). Models are trained on Train-Split-2 with values in this C & Classweight grid and validated against Train-Split-1 (not on Test split)\n",
    "\n",
    "Basis this the best params found are: C 1 Classweights {0: 0.1, 1: 0.9} that resulted in Recall of 87 and Precision of 76 and f1-score of 81. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 0.05 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99572\n",
      "         1.0       0.54      0.87      0.67       110\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.77      0.94      0.83     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99567\n",
      "         1.0       0.57      0.88      0.69       115\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.78      0.94      0.84     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99565\n",
      "         1.0       0.58      0.88      0.70       117\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.79      0.94      0.85     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99563\n",
      "         1.0       0.58      0.87      0.70       119\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.79      0.94      0.85     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.05 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99559\n",
      "         1.0       0.60      0.87      0.71       123\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.80      0.93      0.86     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99556\n",
      "         1.0       0.62      0.87      0.72       126\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.81      0.94      0.86     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99546\n",
      "         1.0       0.66      0.86      0.75       136\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.83      0.93      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99545\n",
      "         1.0       0.66      0.86      0.75       137\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.83      0.93      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99539\n",
      "         1.0       0.70      0.87      0.77       143\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.85      0.93      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 0.1 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99535\n",
      "         1.0       0.72      0.87      0.79       147\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.86      0.94      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99526\n",
      "         1.0       0.76      0.87      0.81       156\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.88      0.94      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99509\n",
      "         1.0       0.79      0.82      0.80       173\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.91      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99506\n",
      "         1.0       0.80      0.81      0.80       176\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.90      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99502\n",
      "         1.0       0.80      0.79      0.80       180\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.90      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for C 1 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99493\n",
      "         1.0       0.82      0.77      0.80       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.89      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.1, 1: 0.9} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99522\n",
      "         1.0       0.78      0.87      0.82       160\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.89      0.93      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.05, 1: 0.95} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99499\n",
      "         1.0       0.81      0.79      0.80       183\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.89      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.04, 1: 0.96} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99496\n",
      "         1.0       0.81      0.78      0.80       186\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.89      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.03, 1: 0.97} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99488\n",
      "         1.0       0.82      0.75      0.78       194\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.88      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for C 10 Classweights {0: 0.02, 1: 0.98} is:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99467\n",
      "         1.0       0.84      0.70      0.76       215\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.92      0.85      0.88     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [0.05, 0.1, 1, 10]\n",
    "ClassWeights =[{0: 0.1, 1: 0.9}, {0: 0.05, 1: 0.95}, {0: 0.04, 1: 0.96}, {0: 0.03, 1: 0.97}, {0: 0.02, 1: 0.98}]\n",
    "for i in C:\n",
    "    for j in ClassWeights:\n",
    "        model_svc = LinearSVC(C=i, class_weight = j)\n",
    "        model_svc.fit(X_s_train2, y_s_train2)\n",
    "        y_s_pred1 = model_svc.predict(X_s_train1)\n",
    "        print(\"Classification Report for C {0} Classweights {1} is: {2}\".format(i, j, classification_report(y_s_pred1, y_s_train1)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Tuning \n",
    "#### Custom search for threshold using the CV blocks.\n",
    "Best C and Classweight parameters found using above custom validation is used for the model. Further the model is cross validated for a range of Thresholds (i.e Decision function in this SVC case) is done. Interestingly the best thresholds found for each of the CV blocks are same i.e 'zero', but this is just a coincidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom search for best threshold for CV block-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_svc = LinearSVC(C=1, class_weight = {0: 0.1, 1: 0.9})\n",
    "model_svc.fit(X_s_train1, y_s_train1)\n",
    "y_scores = model_svc.decision_function(X_s_train2)\n",
    "y_adj_pred = (y_scores >= 0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Threshold -1 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     86806\n",
      "           1       0.95      0.01      0.02     12876\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     99682\n",
      "   macro avg       0.91      0.51      0.48     99682\n",
      "weighted avg       0.88      0.87      0.81     99682\n",
      "\n",
      "Classification Report for Threshold -0.5 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99490\n",
      "           1       0.83      0.72      0.77       192\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.92      0.86      0.89     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 0 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99522\n",
      "           1       0.80      0.83      0.82       160\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.90      0.92      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 0.5 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99559\n",
      "           1       0.64      0.86      0.73       123\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.82      0.93      0.87     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 1 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99581\n",
      "           1       0.52      0.85      0.64       101\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.76      0.93      0.82     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [-1, -0.5, 0, 0.5, 1]\n",
    "for threshold in thresholds:\n",
    "    y_adj_pred = (y_scores >= threshold).astype('int')\n",
    "    print(\"Classification Report for Threshold {0} is: {1}\".format(threshold, classification_report(y_adj_pred, y_s_train2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom search for finding best threshold for CV Block-2\n",
    "The above aproach for CV block-1 is run CV block-2. Interesting Decision Function of '0' (which is also the default) is found to be the best for this block as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_svc = LinearSVC(C=1, class_weight = {0: 0.1, 1: 0.9})\n",
    "model_svc.fit(X_s_train2, y_s_train2)\n",
    "y_scores = model_svc.decision_function(X_s_train1)\n",
    "y_adj_pred = (y_scores >= 0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Threshold -1 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94     89116\n",
      "           1       0.96      0.02      0.03     10566\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     99682\n",
      "   macro avg       0.93      0.51      0.49     99682\n",
      "weighted avg       0.90      0.90      0.85     99682\n",
      "\n",
      "Classification Report for Threshold -0.5 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99489\n",
      "           1       0.83      0.76      0.79       193\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.91      0.88      0.90     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 0 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99526\n",
      "           1       0.76      0.87      0.81       156\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.88      0.94      0.91     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 0.5 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99566\n",
      "           1       0.58      0.90      0.71       116\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.79      0.95      0.85     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n",
      "Classification Report for Threshold 1 is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99592\n",
      "           1       0.44      0.87      0.58        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.72      0.93      0.79     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [-1, -0.5, 0, 0.5, 1]\n",
    "for threshold in thresholds:\n",
    "    y_adj_pred = (y_scores >= threshold).astype('int')\n",
    "    print(\"Classification Report for Threshold {0} is: {1}\".format(threshold, classification_report(y_adj_pred, y_s_train1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding classification report for the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for best params is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     85316\n",
      "         1.0       0.78      0.91      0.84       127\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     85443\n",
      "   macro avg       0.89      0.95      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svc = LinearSVC(C=1, class_weight = {0: 0.1, 1: 0.9})\n",
    "model_svc.fit(X_s_train, y_s_train)\n",
    "y_s_pred1 = model_svc.predict(X_s_test)\n",
    "print(\"Classification Report for best params is {}\".format(classification_report(y_s_pred1, y_s_test)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
